{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df5bcebc",
   "metadata": {},
   "source": [
    "# SmartDynamic: Data Exploration and Analysis\n",
    "\n",
    "This notebook explores the datasets for the SmartDynamic pricing system. We'll analyze product pricing data, customer segments, competitor pricing, and weather/event data to understand patterns that can influence dynamic pricing strategies.\n",
    "\n",
    "## Objectives\n",
    "- Load and examine the structure of our datasets\n",
    "- Visualize price trends and sales velocity\n",
    "- Calculate price elasticity\n",
    "- Analyze competitor pricing patterns\n",
    "- Explore correlations between weather events and sales\n",
    "- Investigate customer segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e620276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Configure matplotlib for better visualization\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Add parent directory to path to enable imports from src\n",
    "sys.path.append('..')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7637ab08",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Product Data\n",
    "\n",
    "Let's load our product dataset and examine its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b47aeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load product data\n",
    "product_data_path = '../data/sample_product_data.csv'\n",
    "products_df = pd.read_csv(product_data_path)\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset shape: {products_df.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "display(products_df.head())\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nSummary statistics:\")\n",
    "display(products_df.describe())\n",
    "\n",
    "# Check data types and missing values\n",
    "print(\"\\nData types and missing values:\")\n",
    "display(pd.DataFrame({\n",
    "    'Data Type': products_df.dtypes,\n",
    "    'Missing Values': products_df.isnull().sum(),\n",
    "    'Missing %': round(products_df.isnull().sum() / len(products_df) * 100, 2)\n",
    "}\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e194f78b",
   "metadata": {},
   "source": [
    "## 2. Visualize Price Trends and Sales Velocity\n",
    "\n",
    "Let's visualize how prices change over time and how they relate to sales velocity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc03058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to datetime\n",
    "products_df['date'] = pd.to_datetime(products_df['date'])\n",
    "\n",
    "# Plotting price trends for each product\n",
    "plt.figure(figsize=(14, 8))\n",
    "for product_id in products_df['product_id'].unique():\n",
    "    product_data = products_df[products_df['product_id'] == product_id]\n",
    "    plt.plot(product_data['date'], product_data['current_price'], marker='o', label=f'Product {product_id}')\n",
    "\n",
    "plt.title('Price Trends Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create interactive plot with Plotly\n",
    "fig = px.line(products_df, x='date', y='current_price', color='product_id',\n",
    "             title='Product Price Trends', markers=True,\n",
    "             labels={'current_price': 'Current Price ($)', 'date': 'Date', 'product_id': 'Product ID'})\n",
    "fig.update_layout(hovermode=\"x unified\")\n",
    "fig.show()\n",
    "\n",
    "# Visualize relationship between price and sales velocity\n",
    "plt.figure(figsize=(16, 6))\n",
    "for i, product_id in enumerate(products_df['product_id'].unique(), 1):\n",
    "    plt.subplot(1, 3, i)\n",
    "    product_data = products_df[products_df['product_id'] == product_id]\n",
    "    \n",
    "    plt.scatter(product_data['current_price'], product_data['sales_velocity'], alpha=0.7)\n",
    "    plt.title(f'Product {product_id}: Price vs. Sales Velocity')\n",
    "    plt.xlabel('Price ($)')\n",
    "    plt.ylabel('Sales Velocity (units/day)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(product_data['current_price'], product_data['sales_velocity'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(product_data['current_price'], p(product_data['current_price']), \"r--\", alpha=0.7)\n",
    "    \n",
    "    # Calculate correlation\n",
    "    corr = np.corrcoef(product_data['current_price'], product_data['sales_velocity'])[0, 1]\n",
    "    plt.annotate(f\"Correlation: {corr:.2f}\", xy=(0.05, 0.95), xycoords='axes fraction')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f92329",
   "metadata": {},
   "source": [
    "## 3. Calculate Price Elasticity\n",
    "\n",
    "Price elasticity measures how changes in price affect demand. It's a critical metric for dynamic pricing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f28dec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate price elasticity\n",
    "def calculate_price_elasticity(df, product_id):\n",
    "    \"\"\"Calculate price elasticity for a product.\"\"\"\n",
    "    product_data = df[df['product_id'] == product_id].copy()\n",
    "    \n",
    "    # Sort by date to ensure proper order for calculations\n",
    "    product_data = product_data.sort_values('date')\n",
    "    \n",
    "    # Calculate percentage changes\n",
    "    product_data['price_pct_change'] = product_data['current_price'].pct_change()\n",
    "    product_data['sales_pct_change'] = product_data['sales_velocity'].pct_change()\n",
    "    \n",
    "    # Calculate elasticity (% change in sales / % change in price)\n",
    "    product_data['price_elasticity'] = product_data['sales_pct_change'] / product_data['price_pct_change']\n",
    "    \n",
    "    return product_data.dropna()  # Drop rows with NaN (first row due to pct_change)\n",
    "\n",
    "# Calculate elasticity for each product\n",
    "elasticity_results = []\n",
    "\n",
    "for product_id in products_df['product_id'].unique():\n",
    "    elasticity_df = calculate_price_elasticity(products_df, product_id)\n",
    "    avg_elasticity = elasticity_df['price_elasticity'].mean()\n",
    "    elasticity_results.append({\n",
    "        'product_id': product_id,\n",
    "        'avg_elasticity': avg_elasticity,\n",
    "        'elasticity_df': elasticity_df\n",
    "    })\n",
    "    print(f\"Product {product_id} - Average Price Elasticity: {avg_elasticity:.2f}\")\n",
    "\n",
    "# Visualize price elasticity over time\n",
    "plt.figure(figsize=(14, 8))\n",
    "for result in elasticity_results:\n",
    "    elasticity_df = result['elasticity_df']\n",
    "    plt.plot(elasticity_df['date'], elasticity_df['price_elasticity'], marker='o', label=f\"Product {result['product_id']}\")\n",
    "\n",
    "plt.axhline(y=-1, color='r', linestyle='--', alpha=0.7, label='Unit Elasticity (-1)')\n",
    "plt.title('Price Elasticity Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price Elasticity')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create a bar chart of average price elasticity by product\n",
    "products = [result['product_id'] for result in elasticity_results]\n",
    "avg_elasticities = [result['avg_elasticity'] for result in elasticity_results]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(products, avg_elasticities)\n",
    "\n",
    "# Color bars based on elasticity values\n",
    "for i, bar in enumerate(bars):\n",
    "    if avg_elasticities[i] > -1:\n",
    "        bar.set_color('skyblue')\n",
    "    else:\n",
    "        bar.set_color('salmon')\n",
    "\n",
    "plt.axhline(y=-1, color='r', linestyle='--', alpha=0.7, label='Unit Elasticity (-1)')\n",
    "plt.title('Average Price Elasticity by Product')\n",
    "plt.xlabel('Product')\n",
    "plt.ylabel('Price Elasticity')\n",
    "plt.grid(True, axis='y')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9377e235",
   "metadata": {},
   "source": [
    "## 4. Competitor Price Analysis\n",
    "\n",
    "Let's analyze competitor pricing data to understand market positioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5e24b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load competitor pricing data\n",
    "competitor_data_path = '../data/competitor_prices.csv'\n",
    "competitor_df = pd.read_csv(competitor_data_path)\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset shape: {competitor_df.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "display(competitor_df.head())\n",
    "\n",
    "# Convert date to datetime\n",
    "competitor_df['date'] = pd.to_datetime(competitor_df['date'])\n",
    "\n",
    "# Merge our pricing data with competitor data\n",
    "merged_df = pd.merge(\n",
    "    products_df[['date', 'product_id', 'current_price']],\n",
    "    competitor_df,\n",
    "    on=['date', 'product_id'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Calculate price differences\n",
    "merged_df['price_difference'] = merged_df['current_price'] - merged_df['competitor_price']\n",
    "merged_df['price_difference_pct'] = (merged_df['price_difference'] / merged_df['competitor_price']) * 100\n",
    "\n",
    "# Analyze price position relative to competitors\n",
    "price_position = merged_df.groupby(['product_id', 'competitor_name'])['price_difference_pct'].mean().reset_index()\n",
    "price_position['position'] = price_position['price_difference_pct'].apply(\n",
    "    lambda x: 'Lower Price' if x < -1 else ('Higher Price' if x > 1 else 'Similar Price')\n",
    ")\n",
    "\n",
    "display(price_position)\n",
    "\n",
    "# Visualize price position\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='product_id', y='price_difference_pct', hue='competitor_name', data=price_position)\n",
    "plt.title('Average Price Position Relative to Competitors')\n",
    "plt.xlabel('Product')\n",
    "plt.ylabel('Price Difference %')\n",
    "plt.axhline(y=0, color='r', linestyle='--', alpha=0.7)\n",
    "plt.grid(True, axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create interactive plot showing price trends with competitors\n",
    "for product_id in products_df['product_id'].unique():\n",
    "    # Filter data for the specific product\n",
    "    product_data = products_df[products_df['product_id'] == product_id]\n",
    "    competitor_data = competitor_df[competitor_df['product_id'] == product_id]\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add our price line\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=product_data['date'], \n",
    "        y=product_data['current_price'],\n",
    "        mode='lines+markers',\n",
    "        name='Our Price',\n",
    "        line=dict(color='blue', width=3)\n",
    "    ))\n",
    "    \n",
    "    # Add competitor price lines\n",
    "    for competitor in competitor_data['competitor_name'].unique():\n",
    "        comp_data = competitor_data[competitor_data['competitor_name'] == competitor]\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=comp_data['date'], \n",
    "            y=comp_data['competitor_price'],\n",
    "            mode='lines+markers',\n",
    "            name=f'{competitor} Price',\n",
    "            line=dict(dash='dot')\n",
    "        ))\n",
    "    \n",
    "    # Customize layout\n",
    "    fig.update_layout(\n",
    "        title=f'Product {product_id} Price Comparison with Competitors',\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='Price ($)',\n",
    "        legend_title='Price Source',\n",
    "        hovermode=\"x unified\"\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f462ee4",
   "metadata": {},
   "source": [
    "## 5. Weather and Event Analysis\n",
    "\n",
    "Let's explore how weather conditions and events might affect sales patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab7f626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weather and event data\n",
    "weather_data_path = '../data/weather_events_data.csv'\n",
    "weather_df = pd.read_csv(weather_data_path)\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset shape: {weather_df.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "display(weather_df.head())\n",
    "\n",
    "# Convert date to datetime\n",
    "weather_df['date'] = pd.to_datetime(weather_df['date'])\n",
    "\n",
    "# Merge weather data with product data\n",
    "# We'll use New York data for demonstration\n",
    "ny_weather = weather_df[weather_df['location'] == 'New York']\n",
    "weather_sales_df = pd.merge(\n",
    "    products_df,\n",
    "    ny_weather[['date', 'temperature', 'precipitation', 'weather_condition', 'event']],\n",
    "    on='date',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Analyze sales velocity by weather condition\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='weather_condition', y='sales_velocity', data=weather_sales_df)\n",
    "plt.title('Sales Velocity by Weather Condition')\n",
    "plt.xlabel('Weather Condition')\n",
    "plt.ylabel('Sales Velocity (units/day)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyze sales velocity by event\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='event', y='sales_velocity', data=weather_sales_df)\n",
    "plt.title('Sales Velocity by Event')\n",
    "plt.xlabel('Event')\n",
    "plt.ylabel('Sales Velocity (units/day)')\n",
    "plt.grid(True, axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create scatter plot of temperature vs. sales velocity\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='temperature', y='sales_velocity', hue='product_id', data=weather_sales_df)\n",
    "plt.title('Temperature vs. Sales Velocity')\n",
    "plt.xlabel('Temperature (Â°F)')\n",
    "plt.ylabel('Sales Velocity (units/day)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(title='Product')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate correlation between temperature and sales velocity\n",
    "temp_sales_corr = weather_sales_df.groupby('product_id').apply(\n",
    "    lambda x: np.corrcoef(x['temperature'], x['sales_velocity'])[0, 1]\n",
    ").reset_index(name='temperature_sales_correlation')\n",
    "\n",
    "display(temp_sales_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0fe243",
   "metadata": {},
   "source": [
    "## 6. Customer Segmentation Analysis\n",
    "\n",
    "Let's analyze the customer segments to understand their characteristics and pricing sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae905f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load customer segmentation data\n",
    "customer_data_path = '../data/customer_segments.csv'\n",
    "customer_df = pd.read_csv(customer_data_path)\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset shape: {customer_df.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "display(customer_df.head())\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nSummary statistics by segment:\")\n",
    "display(customer_df.groupby('segment').agg({\n",
    "    'price_sensitivity': 'mean',\n",
    "    'purchase_frequency': lambda x: x.mode()[0],\n",
    "    'avg_basket_size': 'mean',\n",
    "    'loyalty_score': 'mean'\n",
    "}))\n",
    "\n",
    "# Visualize customer segments\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Price Sensitivity by Segment\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.boxplot(x='segment', y='price_sensitivity', data=customer_df)\n",
    "plt.title('Price Sensitivity by Customer Segment')\n",
    "plt.xlabel('Segment')\n",
    "plt.ylabel('Price Sensitivity')\n",
    "plt.grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 2: Average Basket Size by Segment\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.boxplot(x='segment', y='avg_basket_size', data=customer_df)\n",
    "plt.title('Average Basket Size by Customer Segment')\n",
    "plt.xlabel('Segment')\n",
    "plt.ylabel('Average Basket Size ($)')\n",
    "plt.grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 3: Loyalty Score by Segment\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.boxplot(x='segment', y='loyalty_score', data=customer_df)\n",
    "plt.title('Loyalty Score by Customer Segment')\n",
    "plt.xlabel('Segment')\n",
    "plt.ylabel('Loyalty Score')\n",
    "plt.grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 4: Preferred Category Distribution\n",
    "plt.subplot(2, 2, 4)\n",
    "category_segment = pd.crosstab(customer_df['segment'], customer_df['preferred_category'])\n",
    "category_segment.plot(kind='bar', stacked=False)\n",
    "plt.title('Preferred Category by Customer Segment')\n",
    "plt.xlabel('Segment')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(True, axis='y', alpha=0.3)\n",
    "plt.legend(title='Category')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create scatter plot of price sensitivity vs. loyalty score\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='price_sensitivity', y='loyalty_score', \n",
    "               hue='segment', size='avg_basket_size',\n",
    "               sizes=(50, 200), alpha=0.7, data=customer_df)\n",
    "plt.title('Price Sensitivity vs. Loyalty Score by Customer Segment')\n",
    "plt.xlabel('Price Sensitivity')\n",
    "plt.ylabel('Loyalty Score')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(title='Segment')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7217c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be89b423",
   "metadata": {},
   "source": [
    "## 7. Key Insights and Next Steps\n",
    "\n",
    "Based on our exploratory data analysis, we can draw several insights to guide our dynamic pricing strategy development."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1e3bf0",
   "metadata": {},
   "source": [
    "### Key Insights:\n",
    "\n",
    "1. **Price Elasticity**: Each product has different price elasticity. Products P002 (clothing) appears to be more elastic than P003 (home), indicating that clothing prices should be more carefully managed as customers are more sensitive to price changes.\n",
    "\n",
    "2. **Competitor Pricing**: Our pricing generally positions between Competitor A and B. We often have a price advantage over Competitor A but are slightly higher than Competitor B.\n",
    "\n",
    "3. **Weather Effects**: Sales velocity appears to correlate with weather conditions, with better sales on sunny days for certain product categories.\n",
    "\n",
    "4. **Customer Segmentation**: We have identified three main segments:\n",
    "   - Premium customers: Low price sensitivity, high basket value\n",
    "   - Value Seekers: High price sensitivity, medium purchase frequency\n",
    "   - Occasional shoppers: Medium price sensitivity, low purchase frequency\n",
    "\n",
    "5. **Promotional Impact**: Products show increased sales velocity during promotions, particularly for price-sensitive segments.\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Develop demand forecasting models leveraging the observed patterns in weather and seasonality\n",
    "2. Create segment-specific pricing rules based on price sensitivity\n",
    "3. Implement competitive pricing strategies that maintain appropriate positioning\n",
    "4. Design reinforcement learning agents that can learn optimal pricing strategies\n",
    "5. Build a pricing optimization framework that incorporates all these insights\n",
    "6. Develop SHAP explanations for pricing decisions for business stakeholders"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
